{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wUtMgN0QbyyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sengundo Parcial\n",
        "Nombre Proyecto: Conecta 4\n",
        "Integrantes:\n",
        "1.Barañado Méndez Alexander Nahuel\n",
        "2.Cruz Grimaldez Richard Ausberto\n",
        "3.Fernández Núñez Diego Emiliano\n",
        "4.Blanco Moya Rosa Leonor\n",
        "5.Lizarazu Nava Denis Sergio\n",
        "6.Terrazas Rosado Charly Alexandre"
      ],
      "metadata": {
        "id": "DLkXINBHx-u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class Board():\n",
        "    def __init__(self):\n",
        "        self.state = np.zeros((6, 7))  # Inicializa un tablero de 6 filas por 7 columnas con ceros (vacío).\n",
        "\n",
        "    def valid_moves(self):\n",
        "        return [j for j in range(3) if self.state[0, j] == 0]  # Devuelve una lista de columnas donde la parte superior está vacía, es decir, movimientos válidos.\n",
        "\n",
        "    def update(self, symbol, col):\n",
        "        for row in range(5, -1, -1):  # Empieza desde la última fila (inferior) y busca la primera celda vacía.\n",
        "            if self.state[row, col] == 0:\n",
        "                self.state[row, col] = symbol  # Coloca el símbolo del jugador en esa celda.\n",
        "                return row, col  # Devuelve la posición (fila, columna) donde se hizo la actualización.\n",
        "        raise ValueError(\"Columna llena!\")  # Lanza un error si la columna está llena.\n",
        "\n",
        "    def is_game_over(self):\n",
        "        # Verifica si hay un ganador en filas, columnas o diagonales.\n",
        "        for row in range(6):\n",
        "            for col in range(7):\n",
        "                # Verificación de cuatro en línea horizontal\n",
        "                if col + 3 < 7 and np.all(self.state[row, col:col + 4] == self.state[row, col]) and self.state[row, col] != 0:\n",
        "                    return self.state[row, col]\n",
        "                # Verificación de cuatro en línea vertical\n",
        "                if row + 3 < 6 and np.all(self.state[row:row + 4, col] == self.state[row, col]) and self.state[row, col] != 0:\n",
        "                    return self.state[row, col]\n",
        "                # Verificación de diagonal ascendente\n",
        "                if col + 3 < 7 and row + 3 < 6 and np.all([self.state[row + i, col + i] == self.state[row, col] for i in range(4)]) and self.state[row, col] != 0:\n",
        "                    return self.state[row, col]\n",
        "                # Verificación de diagonal descendente\n",
        "                if col - 3 >= 0 and row + 3 < 6 and np.all([self.state[row + i, col - i] == self.state[row, col] for i in range(4)]) and self.state[row, col] != 0:\n",
        "                    return self.state[row, col]\n",
        "        # Si no hay movimientos válidos, es un empate.\n",
        "        if len(self.valid_moves()) == 0:\n",
        "            return 0\n",
        "        # El juego continúa.\n",
        "        return None\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((6, 7))  # Reinicia el tablero."
      ],
      "metadata": {
        "id": "Ot9X-8iEbzcd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRsrTaKoj1Vq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PEypadt4b-Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Game():\n",
        "    # Método constructor de la clase Game\n",
        "    def __init__(self, player1, player2):\n",
        "        # Asigna un símbolo a cada jugador: el jugador 1 tiene el símbolo 1 y el jugador 2 tiene el símbolo -1\n",
        "        player1.symbol = 1\n",
        "        player2.symbol = -1\n",
        "\n",
        "        # Se crea una lista de jugadores y se les asigna a la propiedad 'players' de la clase\n",
        "        self.players = [player1, player2]\n",
        "\n",
        "        # Se crea una instancia del tablero de juego (supongo que Board es otra clase que no has incluido)\n",
        "        self.board = Board()\n",
        "\n",
        "    # Método que simula juegos entre los dos jugadores de forma iterativa\n",
        "    def selfplay(self, rounds=100):\n",
        "        # Lista para llevar el registro de victorias de cada jugador (0 para jugador 1 y 1 para jugador 2)\n",
        "        wins = [0, 0]\n",
        "\n",
        "        # Bucle principal que se ejecuta durante la cantidad de rondas especificada (por defecto, 100)\n",
        "        for i in range(1, rounds + 1):\n",
        "            # Reseteamos el tablero antes de empezar cada partida\n",
        "            self.board.reset()\n",
        "\n",
        "            # Reseteamos el estado de los jugadores antes de cada juego\n",
        "            for player in self.players:\n",
        "                player.reset()\n",
        "\n",
        "            game_over = False  # Bandera que indica si el juego ha terminado o no\n",
        "\n",
        "            # Bucle que sigue corriendo hasta que el juego termine\n",
        "            while not game_over:\n",
        "                # Cada jugador hace su movimiento en el tablero\n",
        "                for player in self.players:\n",
        "                    # El jugador toma una acción (esto parece depender de un método 'move' del jugador)\n",
        "                    action = player.move(self.board)\n",
        "\n",
        "                    # Se actualiza el tablero con el movimiento del jugador y se obtiene la fila y columna actualizadas\n",
        "                    row, col = self.board.update(player.symbol, action)\n",
        "\n",
        "                    # El jugador actualiza su conocimiento sobre el estado del tablero\n",
        "                    player.update(self.board)\n",
        "\n",
        "                    # Verificamos si el juego ha terminado (puede retornar un símbolo o None si no ha terminado)\n",
        "                    if self.board.is_game_over() is not None:\n",
        "                        # Si el juego terminó, terminamos el bucle interno\n",
        "                        game_over = True\n",
        "                        break\n",
        "\n",
        "            # Llamamos a la función de recompensa al finalizar cada juego\n",
        "            self.reward()\n",
        "\n",
        "            # Comprobamos quién ganó el juego (según el estado final del tablero)\n",
        "            for ix, player in enumerate(self.players):\n",
        "                if self.board.is_game_over() == player.symbol:\n",
        "                    # Incrementamos la victoria del jugador correspondiente\n",
        "                    wins[ix] += 1\n",
        "\n",
        "            # Imprimimos las victorias de los jugadores en ciertas iteraciones\n",
        "            if i in [500, 1000, 5000]:\n",
        "                print(f\"Iteración {i}: Victorias - Jugador 1: {wins[0]}, Jugador 2: {wins[1]}\")\n",
        "\n",
        "        # Al final de las rondas, retornamos la cantidad total de victorias de ambos jugadores\n",
        "        return wins\n",
        "\n",
        "    # Método para asignar recompensas a los jugadores tras cada juego\n",
        "    def reward(self):\n",
        "        # Comprobamos el resultado del juego: None (si el juego no ha terminado), 0 (empate), 1 o -1 (si alguno de los jugadores ganó)\n",
        "        winner = self.board.is_game_over()\n",
        "\n",
        "        if winner == 0:  # Si es empate (0), premiamos a ambos jugadores con 0.5\n",
        "            for player in self.players:\n",
        "                player.reward(0.5)\n",
        "        else:  # Si hubo un ganador, el ganador recibe 1 y el perdedor recibe 0\n",
        "            for player in self.players:\n",
        "                if winner == player.symbol:\n",
        "                    # Recompensamos al ganador con 1\n",
        "                    player.reward(1)\n",
        "                else:\n",
        "                    # Recompensamos al perdedor con 0\n",
        "                    player.reward(0)"
      ],
      "metadata": {
        "id": "mscYwygTb-lN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7ZVxEE0dcDh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self, alpha=0.5, prob_exp=0.5):\n",
        "        # Inicializa los parámetros del agente\n",
        "        self.value_function = {}  # Diccionario que almacena el valor de cada estado del juego (estado -> valor)\n",
        "        self.alpha = alpha         # Tasa de aprendizaje (learning rate), controla cuánto actualiza el agente su conocimiento\n",
        "        self.positions = []        # Lista que guarda todas las posiciones (estados) visitadas durante un juego\n",
        "        self.prob_exp = prob_exp   # Probabilidad de explorar, controla cuánto el agente prefiere explorar en lugar de explotar\n",
        "\n",
        "    def reset(self):\n",
        "        # Resetea el historial de posiciones del agente, se llama al inicio de cada juego\n",
        "        self.positions = []\n",
        "\n",
        "    def move(self, board, explore=True):\n",
        "        # Devuelve la columna donde el agente va a hacer su próximo movimiento\n",
        "        valid_moves = board.valid_moves()  # Obtiene todas las columnas válidas donde el agente puede poner una ficha\n",
        "\n",
        "        # Si el agente está en modo de exploración (explore=True), elige un movimiento aleatorio\n",
        "        if explore and np.random.uniform(0, 1) < self.prob_exp:\n",
        "            return np.random.choice(valid_moves)  # Selección aleatoria de una columna válida\n",
        "\n",
        "        # Si el agente está en modo de explotación (exploitación: el agente usa su conocimiento para tomar la mejor acción)\n",
        "        max_value = -1000  # Inicializa el valor máximo encontrado como muy bajo\n",
        "        for col in valid_moves:\n",
        "            # Para cada columna válida, simula el movimiento en el tablero\n",
        "            next_board = board.state.copy()  # Copia el estado actual del tablero\n",
        "            for row in range(5, -1, -1):  # Busca la fila más baja disponible en la columna actual\n",
        "                if next_board[row, col] == 0:  # Si la celda está vacía (0), se puede hacer un movimiento\n",
        "                    next_board[row, col] = self.symbol  # Realiza el movimiento del agente (su símbolo)\n",
        "                    break  # Sale del bucle una vez realizado el movimiento\n",
        "\n",
        "            # Convierte el estado del tablero en un string para usarlo como una clave en el diccionario\n",
        "            next_state = str(next_board.reshape(6 * 7))\n",
        "            # Obtiene el valor del estado futuro (si no existe en la tabla, toma valor 0)\n",
        "            value = 0 if self.value_function.get(next_state) is None else self.value_function.get(next_state)\n",
        "\n",
        "            # Si el valor del estado es mayor que el valor máximo actual, actualiza el valor máximo y la mejor columna\n",
        "            if value >= max_value:\n",
        "                max_value = value\n",
        "                best_col = col\n",
        "\n",
        "        # Devuelve la columna con el valor máximo estimado\n",
        "        return best_col\n",
        "\n",
        "    def update(self, board):\n",
        "        # Registra la posición (estado del tablero) en la lista de posiciones visitadas\n",
        "        self.positions.append(str(board.state.reshape(6 * 7)))\n",
        "\n",
        "    def reward(self, reward):\n",
        "        # Actualiza la tabla de valores de la función de valor usando el algoritmo TD(0) (Temporal Difference)\n",
        "        # Recorre las posiciones visitadas en orden inverso (desde el final del juego hacia el inicio)\n",
        "        for p in reversed(self.positions):\n",
        "            # Si no existe una entrada para este estado, la inicializamos con 0\n",
        "            if self.value_function.get(p) is None:\n",
        "                self.value_function[p] = 0\n",
        "\n",
        "            # Actualiza el valor del estado utilizando la fórmula TD(0):\n",
        "            # V(s) <- V(s) + α * (R - V(s))\n",
        "            # Donde:\n",
        "            # - V(s) es el valor del estado actual\n",
        "            # - α es la tasa de aprendizaje\n",
        "            # - R es la recompensa obtenida en este estado\n",
        "            self.value_function[p] += self.alpha * (reward - self.value_function[p])\n",
        "\n",
        "            # La recompensa se actualiza para ser el nuevo valor del estado\n",
        "            reward = self.value_function[p]  # Propaga la recompensa hacia los estados anteriores"
      ],
      "metadata": {
        "id": "yGJriZQXcDtt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XULYzMnvcLiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar los agentes\n",
        "agent1 = Agent(prob_exp=0.5)\n",
        "agent2 = Agent()\n",
        "\n",
        "game = Game(agent1, agent2)\n",
        "game.selfplay(1000)"
      ],
      "metadata": {
        "id": "0MP8gDEjcMYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ordenar la función de valor por el valor de la recompensa (de mayor a menor)\n",
        "funcion_de_valor = sorted(agent1.value_function.items(), key=lambda kv: kv[1], reverse=True)\n",
        "\n",
        "# Crear el DataFrame\n",
        "tabla = pd.DataFrame({\n",
        "    'estado': [x[0] for x in funcion_de_valor],  # Estado\n",
        "    'valor': [x[1] for x in funcion_de_valor]    # Valor\n",
        "})\n",
        "\n",
        "# Limitar el número de filas a mostrar (por ejemplo, las primeras 20)\n",
        "tabla_limited = tabla.head(20)\n",
        "\n",
        "# Mejorar la visualización de la tabla\n",
        "tabla_limited.style.set_table_styles(\n",
        "    [{'selector': 'thead th',\n",
        "      'props': [('background-color', '#4CAF50'), ('color', 'white'), ('font-weight', 'bold')]},\n",
        "     {'selector': 'tbody td',\n",
        "      'props': [('text-align', 'center'), ('font-family', 'Arial')]}]\n",
        ").set_properties(**{'border': '1px solid black', 'border-collapse': 'collapse'}).hide(axis='index')\n",
        "\n",
        "# Imprimir la tabla\n",
        "print(tabla_limited)"
      ],
      "metadata": {
        "id": "dvwj1vTrg0yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Datos simulados: asumimos que `total_rewards_p1` y `total_rewards_p2` representan recompensas acumuladas por ronda\n",
        "# Suponiendo 1000 rondas para los agentes\n",
        "rounds = 1000\n",
        "total_rewards_p1 = np.cumsum(np.random.rand(rounds))  # Recompensas acumuladas del jugador 1 (simulado)\n",
        "total_rewards_p2 = np.cumsum(np.random.rand(rounds))  # Recompensas acumuladas del jugador 2 (simulado)\n",
        "\n",
        "# Cálculo de las recompensas promedio\n",
        "average_rewards_p1 = total_rewards_p1 / (np.arange(1, rounds + 1))\n",
        "average_rewards_p2 = total_rewards_p2 / (np.arange(1, rounds + 1))\n",
        "\n",
        "# Configurar la visualización de los gráficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gráfico 1: Recompensas Totales\n",
        "ax1.plot(total_rewards_p1, label=\"Jugador 1\", color='blue')\n",
        "ax1.plot(total_rewards_p2, label=\"Jugador 2\", color='red')\n",
        "ax1.set_title(\"Recompensas Totales\")\n",
        "ax1.set_xlabel(\"Rondas\")\n",
        "ax1.set_ylabel(\"Recompensas Acumuladas\")\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Gráfico 2: Recompensas Promedio\n",
        "ax2.plot(average_rewards_p1, label=\"Jugador 1\", color='blue')\n",
        "ax2.plot(average_rewards_p2, label=\"Jugador 2\", color='red')\n",
        "ax2.set_title(\"Recompensas Promedio\")\n",
        "ax2.set_xlabel(\"Rondas\")\n",
        "ax2.set_ylabel(\"Recompensa Promedio\")\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Mostrar los gráficos\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hiMkw9Z3qzOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class AIPlayer:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def move(self, board):\n",
        "        # Simple AI logic: chooses a random valid move\n",
        "        valid_moves = board.valid_moves()\n",
        "        return random.choice(valid_moves)\n",
        "\n",
        "    def update(self, board):\n",
        "        pass  # No need to update anything for this simple AI\n",
        "\n",
        "    def reset(self):\n",
        "        pass  # No need to reset anything for this simple AI\n",
        "\n",
        "    def reward(self, reward_value):\n",
        "        pass  # Simple AI does not use rewards, but function is needed for compatibility\n"
      ],
      "metadata": {
        "id": "ZBdCbPCaq4yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def display_board(board_state):\n",
        "    plt.imshow(board_state, cmap='cool', origin='upper')\n",
        "    plt.colorbar(ticks=[-1, 0, 1], label='Player')\n",
        "    plt.xticks(range(7))\n",
        "    plt.yticks(range(6))\n",
        "    plt.xlabel('Column')\n",
        "    plt.ylabel('Row')\n",
        "    plt.title('Conecta 4 - Estado del Tablero')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U8dLVG03qfPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of starting a game with a human vs AI setup\n",
        "player1 = AIPlayer(1)  # AI player\n",
        "player2 = AIPlayer(-1)  # AI player as opponent for demonstration (can replace with a human player class)\n",
        "\n",
        "game = Game(player1, player2)\n",
        "game.board.reset()\n",
        "\n",
        "# Simulate a single game between two AI players, displaying the board after each move\n",
        "game_over = False\n",
        "while not game_over:\n",
        "    for player in game.players:\n",
        "        action = player.move(game.board)\n",
        "        game.board.update(player.symbol, action)\n",
        "        display_board(game.board.state)\n",
        "        if game.board.is_game_over() is not None:\n",
        "            game_over = True\n",
        "            break\n",
        "\n",
        "winner = game.board.is_game_over()\n",
        "if winner == 0:\n",
        "    print(\"Empate\")\n",
        "elif winner == 1:\n",
        "    print(\"Jugador 1 (IA) gana\")\n",
        "else:\n",
        "    print(\"Jugador 2 (IA) gana\")"
      ],
      "metadata": {
        "id": "quJBFiAZqzBp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}